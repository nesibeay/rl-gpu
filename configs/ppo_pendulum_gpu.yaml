# --- PPO Pendulum (GPU 64x64) stable ---
env_id: Pendulum-v1
seed: 1
total_timesteps: 1200000

num_envs: 64
rollout_steps: 64               # 4096 steps/update

n_epochs: 4                     # ↓ fewer, gentler passes
minibatch_size: 1024            # 4 minibatches per update
gamma: 0.99
gae_lambda: 0.95
clip_coef: 0.2
vf_clip_coef: 0.2
ent_coef: 0.02                  # a bit more exploration for Pendulum
vf_coef: 0.5
max_grad_norm: 0.5

actor_hidden_sizes: [64, 64]
critic_hidden_sizes: [64, 64]
activation: tanh

lr: 2.0e-4                      # slightly lower when parallelism ↑
lr_anneal: linear

use_tanh_squash: true
adv_norm: true
use_value_clip: true
target_kl: 0.015

# NEW: the two “unlockers”
reward_scale: 0.1               # scale rewards before GAE/returns
obs_norm: true                  # running mean/std on observations

use_compile: true               # OK on GPU
float32_matmul_precision: high  # TF32 path on NVIDIA
